{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0cc24c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, time\n",
    "from tensorflow.keras.models import model_from_json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33caba26",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43efcce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion detection model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open('emotion_model.json', 'r') as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "\n",
    "emotion_model = model_from_json(loaded_model_json)\n",
    "\n",
    "emotion_model.load_weights('emotion_model_weights.h5')\n",
    "\n",
    "emotion_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"Emotion detection model loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a63150e",
   "metadata": {},
   "source": [
    "Optimizer: 'adam' - adaptive learning rate algorithm, good for most deep learning tasks.\n",
    "\n",
    "Loss function: 'categorical_crossentropy' - standard for multi-class classification (emotions are likely categories like happy, sad, angry, etc.).\n",
    "\n",
    "Metrics: ['accuracy'] - tracks classification accuracy during evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1f0076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face recognition dataset prepared and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_path = \"Student/Original Images\"\n",
    "\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "\n",
    "for student_name in os.listdir(dataset_path):\n",
    "    student_folder = os.path.join(dataset_path, student_name)\n",
    "    if not os.path.isdir(student_folder):\n",
    "        continue\n",
    "\n",
    "    for image_name in os.listdir(student_folder):\n",
    "        image_path = os.path.join(student_folder, image_name)\n",
    "\n",
    "        image = face_recognition.load_image_file(image_path) #Loads image from disk into numpy array format\n",
    "        face_locations = face_recognition.face_locations(image) #Tells the system where faces are before encoding them\n",
    "        face_encodings = face_recognition.face_encodings(image, face_locations)  #Converts detected faces into 128-dimensional vectors (numerical fingerprints)\n",
    " \n",
    "        for encoding in face_encodings:\n",
    "            known_face_encodings.append(encoding)\n",
    "            known_face_names.append(student_name)\n",
    "\n",
    "with open(\"face_encodings.pkl\", \"wb\") as f:\n",
    "    pickle.dump((known_face_encodings, known_face_names), f) #Converts Python objects to binary format for storage.\n",
    "\n",
    "print(\"Face recognition dataset prepared and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6065125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open(\"face_encodings.pkl\", \"rb\") as f:\n",
    "    known_face_encodings, known_face_names = pickle.load(f)\n",
    "\n",
    "with open('emotion_model.json', 'r') as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "emotion_model = model_from_json(loaded_model_json)\n",
    "emotion_model.load_weights('emotion_model_weights.h5')\n",
    "emotion_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "emotion_labels = ['surprise', 'fear', 'disgust', 'happy', 'sad', 'angry', 'neutral']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6376fcae",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0ca5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Attendance marked and saved to attendance.csv\n"
     ]
    }
   ],
   "source": [
    "attendance = {}\n",
    "\n",
    "start_time = time(9, 30)\n",
    "end_time = time(10, 0)\n",
    "\n",
    "def is_within_time_window():\n",
    "    current_time = datetime.now().time()\n",
    "    return start_time <= current_time <= end_time\n",
    "\n",
    "def detect_and_mark_attendance(test_images_folder=\"Student/atest\", output_csv=\"attendance.csv\"):\n",
    "    for image_name in os.listdir(test_images_folder):\n",
    "        image_path = os.path.join(test_images_folder, image_name)\n",
    "        image = face_recognition.load_image_file(image_path)\n",
    "        face_locations = face_recognition.face_locations(image)\n",
    "        face_encodings = face_recognition.face_encodings(image, face_locations)\n",
    "\n",
    "        image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "\n",
    "            name = \"Unknown\"\n",
    "            if matches:\n",
    "                best_match_index = np.argmin(face_distances)\n",
    "                if matches[best_match_index]:\n",
    "                    name = known_face_names[best_match_index]\n",
    "\n",
    "            if name != \"Unknown\" and is_within_time_window():\n",
    "                face_img = image_bgr[top:bottom, left:right]\n",
    "                face_img = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)  \n",
    "                face_img = cv2.resize(face_img, (48, 48))  \n",
    "            \n",
    "                face_img = face_img.astype('float32') / 255.0\n",
    "                face_img = np.expand_dims(face_img, axis=0)\n",
    "                face_img = np.expand_dims(face_img, axis=-1)\n",
    "\n",
    "                emotion_prediction = emotion_model.predict(face_img)\n",
    "                emotion_label = emotion_labels[np.argmax(emotion_prediction)]\n",
    "\n",
    "                timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                attendance[name] = {\"Time\": timestamp, \"Status\": \"Present\", \"Emotion\": emotion_label}\n",
    "\n",
    "    # After processing images, mark absent students\n",
    "    all_students = set(known_face_names)\n",
    "    present_students = set(attendance.keys())\n",
    "    for student in all_students - present_students:\n",
    "        attendance[student] = {\"Time\": \"\", \"Status\": \"Absent\", \"Emotion\": \"\"}\n",
    "\n",
    "\n",
    "    attendance_df = pd.DataFrame.from_dict(attendance, orient='index')\n",
    "    attendance_df.index.name = 'Student Name'\n",
    "    attendance_df.to_csv(output_csv)\n",
    "\n",
    "    print(f\"Attendance marked and saved to {output_csv}\")\n",
    "\n",
    "detect_and_mark_attendance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852c23fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
